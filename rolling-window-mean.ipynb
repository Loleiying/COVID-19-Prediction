{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom datetime import date\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ntrain = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/test.csv\")\nsubmit = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-4/submission.csv\")\nweather = pd.read_csv(\"/kaggle/input/weather-data/training_data_with_weather_info_week_4.csv\")","execution_count":44,"outputs":[{"output_type":"stream","text":"/kaggle/input/weather-data/training_data_with_weather_info_week_1.csv\n/kaggle/input/weather-data/__resultx__.html\n/kaggle/input/weather-data/custom.css\n/kaggle/input/weather-data/__notebook__.ipynb\n/kaggle/input/weather-data/__results__.html\n/kaggle/input/weather-data/__output__.json\n/kaggle/input/weather-data/training_data_with_weather_info_week_4.csv\n/kaggle/input/weather-data/__results___files/__results___3_0.png\n/kaggle/input/weather-data/__results___files/__results___2_1.png\n/kaggle/input/covid19-global-forecasting-week-4/train.csv\n/kaggle/input/covid19-global-forecasting-week-4/submission.csv\n/kaggle/input/covid19-global-forecasting-week-4/test.csv\n/kaggle/input/covid19formattedweatherjan22march24/covid_dataset.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# Data Transformation\n1.  Combine the 'Country_Region' and 'Province_State' columns into 'country_province'.\n2.  Calculate the cumulative cases and fatalities for each country_province as 'cumCases' and 'cumDeath'\n3.  Chagnge the datatype of 'Date' to datetime  \n~~4.  Remove the zero days for each country_province.~~ **Keep zeros to see if it fits the model better**\n5.  Add weather data for each day\n6.  Add 'prevCases' and 'prevDeath' for train data\n7.  Add 'Days' since Jan-22-2020\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def dataTrans(df, purpose):\n    # 1. Combine the Country_Region and Province_State columns into country_province.\n    df.Province_State[df['Province_State'].isnull()] = '' # change the null to empty string\n    df['country_province'] = df.apply(lambda x: x.Country_Region if x.Province_State == '' else x.Country_Region+'_'+x.Province_State, axis = 1)\n    # 3. Chagnge the datatype of Date to datetime\n    df['Date'] = pd.to_datetime(df['Date'], infer_datetime_format=True)\n    # 4. Remove the zero case days for each country_province.\n    #df_filtered = df_cum[df_cum.ConfirmedCases > 0.0]\n    #df_filtered.head(10)  \n    # 6.  Add a column for DaysSince jan-22-2020\n    df[\"Days\"] = (df.Date - pd.Timestamp('2020-01-22 00:00:00')).dt.days\n    \n    \n    ##################################################################################################\n    # for training dataset only\n    if (purpose == 'train'):\n        # 2. Calculate the cumulative cases and fatalities for each country_province for the train data\n        # 5.  Add column for prevCases and prevDeath\n        cumCases = pd.Series()\n        cumDeath = pd.Series()\n        prevCases = pd.Series()\n        prevDeath = pd.Series()\n        for region in df.country_province.unique():\n            cases = df.ConfirmedCases[df.country_province==region].cumsum()\n            death = df.Fatalities[df.country_province==region].cumsum()\n            cumCases = pd.concat([cumCases,cases])\n            cumDeath = pd.concat([cumDeath,death])\n            prevCases = pd.concat([prevCases,pd.Series([0]),cases.iloc[:len(cases)-1]])\n            prevDeath = pd.concat([prevDeath,pd.Series([0]),death.iloc[:len(death)-1]])\n        prevCases = prevCases.reset_index(drop=True)\n        prevDeath = prevDeath.reset_index(drop=True)\n        #print(len(cumCases), len(cumDeath), df.shape[0])\n        df_cum = pd.concat([df,cumCases,cumDeath,prevCases,prevDeath], axis=1)\n        #print(df.shape, df_cum.shape)\n        df_cum = df_cum.rename(columns={0:'cumCases', 1:'cumDeath', 2:'prevCases', 3:'prevDeath'})\n        return df_cum#, df_filtered\n    ######################################################################################################\n    else:\n        return df","execution_count":45,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = dataTrans(train,'train')\n#df_test = dataTrans(test,'')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[df_train.country_province == 'Zimbabwe'] #\n#df_train.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":47,"outputs":[{"output_type":"execute_result","execution_count":47,"data":{"text/plain":"   Id Province_State Country_Region        Date  ConfirmedCases  Fatalities  \\\n0   1            NaN    Afghanistan  2020-01-22             0.0         0.0   \n1   2            NaN    Afghanistan  2020-01-23             0.0         0.0   \n2   3            NaN    Afghanistan  2020-01-24             0.0         0.0   \n3   4            NaN    Afghanistan  2020-01-25             0.0         0.0   \n4   5            NaN    Afghanistan  2020-01-26             0.0         0.0   \n\n  country+province   Lat  Long  day_from_jan_first  ...   min   max    stp  \\\n0     Afghanistan-  33.0  65.0                  22  ...  33.6  54.9  999.9   \n1     Afghanistan-  33.0  65.0                  23  ...  32.7  55.9  999.9   \n2     Afghanistan-  33.0  65.0                  24  ...  36.9  43.2  999.9   \n3     Afghanistan-  33.0  65.0                  25  ...  37.9  56.3  999.9   \n4     Afghanistan-  33.0  65.0                  26  ...  36.1  53.1  999.9   \n\n      slp  dewp        rh        ah  wdsp   prcp  fog  \n0  1024.3  27.4  0.545709  0.186448   9.4   0.00    0  \n1  1020.8  22.8  0.461259  0.163225  14.9  99.99    1  \n2  1018.6  34.5  0.801794  0.325375  10.4   0.17    1  \n3  1018.0  37.8  0.728175  0.214562   6.1   0.57    1  \n4  1014.8  33.2  0.685513  0.231656  10.8   0.00    1  \n\n[5 rows x 21 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Province_State</th>\n      <th>Country_Region</th>\n      <th>Date</th>\n      <th>ConfirmedCases</th>\n      <th>Fatalities</th>\n      <th>country+province</th>\n      <th>Lat</th>\n      <th>Long</th>\n      <th>day_from_jan_first</th>\n      <th>...</th>\n      <th>min</th>\n      <th>max</th>\n      <th>stp</th>\n      <th>slp</th>\n      <th>dewp</th>\n      <th>rh</th>\n      <th>ah</th>\n      <th>wdsp</th>\n      <th>prcp</th>\n      <th>fog</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>Afghanistan</td>\n      <td>2020-01-22</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Afghanistan-</td>\n      <td>33.0</td>\n      <td>65.0</td>\n      <td>22</td>\n      <td>...</td>\n      <td>33.6</td>\n      <td>54.9</td>\n      <td>999.9</td>\n      <td>1024.3</td>\n      <td>27.4</td>\n      <td>0.545709</td>\n      <td>0.186448</td>\n      <td>9.4</td>\n      <td>0.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>NaN</td>\n      <td>Afghanistan</td>\n      <td>2020-01-23</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Afghanistan-</td>\n      <td>33.0</td>\n      <td>65.0</td>\n      <td>23</td>\n      <td>...</td>\n      <td>32.7</td>\n      <td>55.9</td>\n      <td>999.9</td>\n      <td>1020.8</td>\n      <td>22.8</td>\n      <td>0.461259</td>\n      <td>0.163225</td>\n      <td>14.9</td>\n      <td>99.99</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>NaN</td>\n      <td>Afghanistan</td>\n      <td>2020-01-24</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Afghanistan-</td>\n      <td>33.0</td>\n      <td>65.0</td>\n      <td>24</td>\n      <td>...</td>\n      <td>36.9</td>\n      <td>43.2</td>\n      <td>999.9</td>\n      <td>1018.6</td>\n      <td>34.5</td>\n      <td>0.801794</td>\n      <td>0.325375</td>\n      <td>10.4</td>\n      <td>0.17</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>Afghanistan</td>\n      <td>2020-01-25</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Afghanistan-</td>\n      <td>33.0</td>\n      <td>65.0</td>\n      <td>25</td>\n      <td>...</td>\n      <td>37.9</td>\n      <td>56.3</td>\n      <td>999.9</td>\n      <td>1018.0</td>\n      <td>37.8</td>\n      <td>0.728175</td>\n      <td>0.214562</td>\n      <td>6.1</td>\n      <td>0.57</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>Afghanistan</td>\n      <td>2020-01-26</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Afghanistan-</td>\n      <td>33.0</td>\n      <td>65.0</td>\n      <td>26</td>\n      <td>...</td>\n      <td>36.1</td>\n      <td>53.1</td>\n      <td>999.9</td>\n      <td>1014.8</td>\n      <td>33.2</td>\n      <td>0.685513</td>\n      <td>0.231656</td>\n      <td>10.8</td>\n      <td>0.00</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 21 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Time Series Regression\n## Rolling window regression\n1. Select one country to work with ('Afghanistan')\n2. Create rolling windows=10 based on 70 days of observation\n3. Perform regression on rolling windows\n4. Select 10 country_regions to work with (first 10)\n5. Repeat step 2 to 3"},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_cum.country_province.unique()\n\n# 1. Select one country to work with ('Germany')\ndf = train_filtered[train_filtered.country_province == 'Afghanistan']#train_cum[train_cum.country_province == 'Germany']\ndf.shape\n\ndf['ConfirmedCases'].plot.line(logy=True)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# 2. Create rolling windows=10 based on 70 days of observation\nrolling_mean = df[['Date','cumCases']].rolling(10).mean()\ndf[['ConfirmedCases','Fatalities','cumCases','cumDeath']].plot.line(logy=True)\nrolling_mean.plot.line(logy=True)\n\n\n# 3. Perform random forest regression on rolling windows\n\n# set up dataset for train, test, and validation\nX = rolling_mean.fillna(0)\ny = df.cumCases\n\nX_train = X[X.index < 50]\ny_train = y[y.index < 50]\n\nX_test = X[X.index >= 50]\ny_test = y[y.index >= 50]\n\nfrom sklearn.ensemble.forest import RandomForestRegressor\n\n\n# build our RF model\nRF_Model = RandomForestRegressor(n_estimators=100,\n                                 max_features=1,\n                                 oob_score=True)\n\n# let's get the labels and features in order to run our model fitting\nlabels = y_train#[:, None]\nfeatures = X_train#[:, None]\n\n# Fit the RF model with features and labels.\nrgr=RF_Model.fit(features, labels)\n\n# Now that we've run our models and fit it, let's create\n# dataframes to look at the results\nX_test_predict=pd.DataFrame(\n    rgr.predict(X_test)).rename(\n    columns={0:'predicted_cases'}).set_index('predicted_cases')\nX_train_predict=pd.DataFrame(\n    rgr.predict(X_train)).rename(\n    columns={0:'predicted_cases'}).set_index('predicted_cases')\n\n# combine the training and testing dataframes to visualize\n# and compare.\nRF_predict = X_train_predict.append(X_test_predict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RF_predict.tail(50)#[['cumCases', 'predicted_cases']].plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import StackingRegressor\nfrom sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.ensemble import HistGradientBoostingRegressor\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import RidgeCV\n\n# create models\nestimators = [('Random Forest',RandomForestRegressor(random_state=42)),\n         ('Lasso',LassoCV()),\n         ('Gradient Boosting', HistGradientBoostingRegressor(random_state=0))]\nstackingRegressor = StackingRegressor(estimators=estimators, final_estimator=RidgeCV())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nimport numpy as np\nfrom sklearn.model_selection import cross_validate, cross_val_predict\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}